{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe8cf47-78b4-486a-a6d0-ffde60850aa0",
   "metadata": {},
   "source": [
    "## Search for overlapping Sentinel-1 and Sentinel-2 in Fram Strait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d388f-32cc-4f03-aeb9-fadf2e242ebb",
   "metadata": {},
   "source": [
    "## This notebook searches for overlapping Sentinel-1 (EW GRDM) and Sentinel-2 (L1C, cloud coverage 0-30%) data.\n",
    "### The search is implemented using the 'sentinelSAT' package, which is a powerful search API for the Copernicus Scihub database.\n",
    "\n",
    "### Two requirement to run this script:\n",
    "### 1) have a user account on Copernicus Open Access Hub (Scihub): https://scihub.copernicus.eu/dhus/#/home\n",
    "### 2) create a file named .env in the directory 'S1_sea_ice_classification'. In this file, save your username and password for Copernicus SciHub like this:\n",
    "### DHUS_USER=\"scihub_username\"\n",
    "### DHUS_PASSWORD=\"scihub_password\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b58a4e61-67e4-48fd-9bab-3b6319524880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from dateparser import parse\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb50c2-8f8f-47d0-954c-d35c6a9e01eb",
   "metadata": {},
   "source": [
    "#### Load environment variables containing username and password for Copernicus Scihub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39747ddd-229f-49ad-a252-6573f1d8e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "    \n",
    "try:\n",
    "    os.environ[\"DHUS_USER\"]\n",
    "except:\n",
    "    logger.error(\"The environment variable 'DHUS_USER' is not set! Exiting...\")\n",
    "    raise KeyError(\"The environment variable 'DHUS_USER' is not set!\")\n",
    "\n",
    "try:\n",
    "    os.environ[\"DHUS_PASSWORD\"]\n",
    "except:\n",
    "    logger.error(\"The environment variable 'DHUS_PASSWORD' is not set! Exiting...\")\n",
    "    raise KeyError(\"The environment variable 'DHUS_PASSWORD' is not set!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9338397b-7c04-4064-bc7a-96b1bc33d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 S1 scenes with overlapping S2 imagery.\n"
     ]
    }
   ],
   "source": [
    "# establish connection to Copernicus Scihub\n",
    "api = SentinelAPI(os.environ[\"DHUS_USER\"], os.environ[\"DHUS_PASSWORD\"])\n",
    "\n",
    "# search over Fram Strait for S1 imagery (from 1st Dec 2020 to 1st June 2021)\n",
    "# use custom geojson files containing search polygon\n",
    "area = './rois/Fram_Strait.geojson'\n",
    "polygon_path = Path(area).expanduser().absolute()\n",
    "\n",
    "# set start- and endtime for search\n",
    "starttime = \"2020-03-01\"\n",
    "endtime = \"2020-05-01\"\n",
    "\n",
    "# area relation for S1, 'Contains' returns all hits where the ROI polygon is entirely WITHIN the footprint of the S1\n",
    "s1_area_relation = 'Contains'\n",
    "    \n",
    "starttime = parse(starttime, settings={\"DATE_ORDER\": \"YMD\"})\n",
    "endtime = parse(endtime, settings={\"DATE_ORDER\": \"YMD\"})\n",
    "\n",
    "# query for S1 products that match our search criteria\n",
    "s1_products = api.query(\n",
    "                geojson_to_wkt(read_geojson(polygon_path)),\n",
    "                date=(starttime, endtime),\n",
    "                platformname=\"Sentinel-1\",\n",
    "                producttype=\"GRD\",\n",
    "                area_relation=s1_area_relation,\n",
    "                )\n",
    "\n",
    "# create empty dictionary that will contain S1 identifiers as keys, and the overlapping S2 identifier(s) as values\n",
    "s1_s2_overlap = {}\n",
    "\n",
    "# iterate over query results to check for overlapping S2\n",
    "for product in s1_products:\n",
    "\n",
    "    # retrieve identifier and timestamp of the S1 product\n",
    "    s1_identifier = s1_products[product]['identifier']\n",
    "    s1_timestamp = s1_products[product]['beginposition']\n",
    "\n",
    "    # look for S2 imagery taken 2 hours before or after S1 acquisition\n",
    "    timedelta = datetime.timedelta(hours = 5) \n",
    "    s2_starttime = s1_timestamp - timedelta\n",
    "    s2_endtime = s1_timestamp + timedelta\n",
    "\n",
    "    # area relation for S2, 'intersects' returns all hits where the ROI polygon INTERSECTS with the S1 footprint\n",
    "    s2_area_relation = 'Intersects'\n",
    "\n",
    "    # query for overlapping Sentinel-2 optical images\n",
    "    s2_products = api.query(\n",
    "                        area = geojson_to_wkt(read_geojson(polygon_path)),\n",
    "                        date = (s2_starttime, s2_endtime),\n",
    "                        platformname=\"Sentinel-2\",\n",
    "                        processinglevel=\"Level-1C\",\n",
    "                        cloudcoverpercentage=(0, 30),\n",
    "                        area_relation=s2_area_relation,\n",
    "                        )\n",
    "    \n",
    "    # if overlapping S2 scenes found, add the S1 id and corresponding S2 query results in dictionary\n",
    "    if not len(s2_products) == 0:\n",
    "        s2_id_list = []\n",
    "        \n",
    "        # loop over S2 search results and extract S2 product identifier\n",
    "        for s2product in s2_products:\n",
    "            s2_identifier = s2_products[s2product]['identifier']\n",
    "            s2_id_list.append(s2_identifier)\n",
    "        s1_s2_overlap[s1_identifier] = s2_id_list\n",
    "            \n",
    "print('Found', len(s1_s2_overlap), 'S1 scenes with overlapping S2 imagery.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66ee3a12-52fb-4b08-80bf-b9f227d9d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results saved to txt files!\n"
     ]
    }
   ],
   "source": [
    "# save dictionary results to text files, these text files can then be used to download the S1 and S2 products on e.g. Creodias\n",
    "for key, value in s1_s2_overlap.items(): \n",
    "    with open(f\"./search_results_Fram_Strait/{key}.txt\", 'w') as f:\n",
    "        f.write('\\n'.join(value))\n",
    "        \n",
    "print('Search results saved in \"search_results_Fram_Strait\" folder!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db93bec-5f79-49c9-8b48-0db9a9030abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
