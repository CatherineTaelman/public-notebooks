{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b58a4e61-67e4-48fd-9bab-3b6319524880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from dateparser import parse\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0833b4dd-a146-4f2d-8951-78cd5626e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This notebook searches for overlapping Sentinel-1 (EW GRDM) and Sentinel-2 (L1C, cloud coverage 0-30%) data.\n",
    "### The search is implemented using the 'sentinelsat' package, which is a powerful search API for the Copernicus Scihub database.\n",
    "\n",
    "### Two requirement to run this script:\n",
    "### 1) have a user account on Copernicus Open Access Hub: https://scihub.copernicus.eu/dhus/#/home\n",
    "### 2) create a file called .env in the directory 'S1_sea_ice_classification'. In this file, save your username and password for SciHub like this:\n",
    "### DHUS_USER=<scihub_username>\n",
    "### DHUS_PASSWORD=<scihub_password>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb50c2-8f8f-47d0-954c-d35c6a9e01eb",
   "metadata": {},
   "source": [
    "#### Load environment variables containing username and password for Copernicus Scihub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39747ddd-229f-49ad-a252-6573f1d8e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "    \n",
    "try:\n",
    "    os.environ[\"DHUS_USER\"]\n",
    "except:\n",
    "    logger.error(\"The environment variable 'DHUS_USER' is not set! Exiting...\")\n",
    "    raise KeyError(\"The environment variable 'DHUS_USER' is not set!\")\n",
    "\n",
    "try:\n",
    "    os.environ[\"DHUS_PASSWORD\"]\n",
    "except:\n",
    "    logger.error(\"The environment variable 'DHUS_PASSWORD' is not set! Exiting...\")\n",
    "    raise KeyError(\"The environment variable 'DHUS_PASSWORD' is not set!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7e5027-e0e9-4573-95ae-a1f5b55780b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cta014\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"DHUS_USER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9338397b-7c04-4064-bc7a-96b1bc33d1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1c3e1e58254fe6a35e73ceaa1df490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Querying products:  23%|##3       | 100/426 [00:00<?, ?product/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4706b028dcac4baaa5b24da8d5fbc665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Querying products:  96%|#########6| 100/104 [00:00<?, ?product/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 S1 scenes with overlapping S2 imagery.\n",
      "['7a9d39fe-7343-43d5-bbfb-2c1c23b873f2', 'e2e44b29-43c5-48f8-b0b2-e9bd150dc542', '73ed5fe4-eada-4ed8-aa9a-83d9f2218777', '11693167-8de4-4529-a779-a00290346b19', '78f1e137-189a-4743-a31a-52537468e780', '6fde56ac-b85b-444e-be41-194d0a686b88', '88c9e908-8c08-4e6a-92fd-e7ecb6e8d060', '81c26764-5ac0-42b7-9917-3d647dde6ead', '42f92139-78a1-4971-a9ed-ec448cf8ecfa', '9c620dee-4040-4b56-9ec4-203e4bfcd3f8', '858d48a5-afe4-4f6c-93f3-bef2bf0116b2', '26fa1a72-8ad4-4eb8-9852-d1adce9782b0', 'a5d38ae2-bbc4-4548-a64a-4fc55dc9bf86', 'fb0d3244-469e-4ff6-9bbe-558bd0b14844', 'f05595d8-7223-4120-8578-7e05348f5245']\n"
     ]
    }
   ],
   "source": [
    "# establish connection to Copernicus Scihub\n",
    "api = SentinelAPI(os.environ[\"DHUS_USER\"], os.environ[\"DHUS_PASSWORD\"])\n",
    "\n",
    "# search over Fram Strait for S1 imagery (from 1st Dec 2020 to 1st June 2021)\n",
    "# use custom geojson files containing search polygon\n",
    "area = './rois/Fram_Strait.geojson'\n",
    "polygon_path = Path(area).expanduser().absolute()\n",
    "\n",
    "# search from 1st March 2021 to 1st May 2021\n",
    "starttime = \"2020-03-01\"\n",
    "endtime = \"2020-05-01\"\n",
    "starttime = parse(starttime, settings={\"DATE_ORDER\": \"YMD\"})\n",
    "endtime = parse(endtime, settings={\"DATE_ORDER\": \"YMD\"})\n",
    "\n",
    "# query for specific product\n",
    "s1_products = api.query(\n",
    "                geojson_to_wkt(read_geojson(polygon_path)),\n",
    "                date=(starttime, endtime),\n",
    "                platformname=\"Sentinel-1\",\n",
    "                producttype=\"GRD\",\n",
    "                )\n",
    "\n",
    "s1_list_with_overlap = []\n",
    "s1_s2_overlap = {}\n",
    "\n",
    "# iterate over query results to check for overlapping S2\n",
    "for product in s1_products:\n",
    "\n",
    "    # retrieve some properties of the S1 product\n",
    "    s1_footprint = s1_products[product]['footprint']\n",
    "    s1_identifier = s1_products[product]['identifier']\n",
    "    s1_timestamp = s1_products[product]['beginposition']\n",
    "\n",
    "    # look for S2 imagery taken 2 hours before or after S1 acquisition\n",
    "    timedelta = datetime.timedelta(hours = 2) \n",
    "    s2_starttime = s1_timestamp - timedelta\n",
    "    s2_endtime = s1_timestamp + timedelta\n",
    "\n",
    "    # query for overlapping Sentinel-2 optical images\n",
    "    s2_products = api.query(area = s1_footprint,\n",
    "                            date = (s2_starttime, s2_endtime),\n",
    "                            platformname=\"Sentinel-2\",\n",
    "                            processinglevel=\"Level-1C\",\n",
    "                            cloudcoverpercentage=(0, 30)\n",
    "                            )\n",
    "    \n",
    "    # if overlapping S2 scenes found, add the S1 id and corresponding S2 query results in dictionary\n",
    "    if not len(s2_products) == 0:\n",
    "        s1_list_with_overlap.append(product)\n",
    "        if len(s2_products) == 1:\n",
    "            for s2product in s2_products:\n",
    "                s2_identifier = s2_products[s2product]['identifier']\n",
    "                s1_s2_overlap[s1_identifier] = s2_identifier\n",
    "        elif len(s2_products) > 1:\n",
    "            s2_id_list = []\n",
    "            for s2product in s2_products:\n",
    "                s2_identifier = s2_products[s2product]['identifier']\n",
    "                s2_id_list.append(s2_identifier)\n",
    "            s1_s2_overlap[s1_identifier] = s2_id_list\n",
    "            \n",
    "# this list is contains the S1 scenes that have overlapping S2 imagery\n",
    "print('Found', len(s1_list_with_overlap), 'S1 scenes with overlapping S2 imagery.')\n",
    "print(s1_list_with_overlap)\n",
    "\n",
    "# make copy of the original query results\n",
    "s1_products_with_overlap = s1_products.copy()\n",
    "\n",
    "# loop over all original query results and only keep the ones that have overlapping S2\n",
    "for product in s1_products:\n",
    "    if not product in s1_list_with_overlap:\n",
    "        del s1_products_with_overlap[product]\n",
    "        \n",
    "# 's1_products_with_overlap' can be direclty entered into the api.download_all() function. This will then download all S1 images that have overlapping S2 imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e44f0a-ff67-4551-9600-88770157ae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(s1_products_with_overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "923b4349-11c9-4367-91b8-5234389a5810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['b1147e36-9e0f-4ff5-93a0-f5e2d00da8ab', 'c31e230a-524d-4ab0-a442-457ffc65a93b'])\n"
     ]
    }
   ],
   "source": [
    "print(s1_products_with_overlap.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddb2a98e-ec28-4c01-8f70-45927170d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['S1B_EW_GRDM_1SDH_20210331T174023_20210331T174045_026262_032261_26FA', 'S1A_EW_GRDM_1SDH_20210316T180541_20210316T180652_037027_045B91_98E3'])\n"
     ]
    }
   ],
   "source": [
    "print(s1_s2_overlap.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc6032f-d205-4f78-805b-165619d63b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S2B_MSIL1C_20210331T154809_N0300_R054_T26XMN_20210331T174855', 'S2B_MSIL1C_20210331T154809_N0300_R054_T26XMM_20210331T174855']\n"
     ]
    }
   ],
   "source": [
    "print(s1_s2_overlap['S1B_EW_GRDM_1SDH_20210331T174023_20210331T174045_026262_032261_26FA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630712d-6c9b-40c6-9922-c46a00a32b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
